# Anti-Corrupt — How It Works

> A practical guide to every tool, where data lives, how data flows, and what
> requires a real API key vs. what runs completely offline.

---

## Table of Contents

1. [Big Picture — The Pipeline](#1-big-picture--the-pipeline)
2. [Where Data Is Stored](#2-where-data-is-stored)
3. [Knowledge Base (static data)](#3-knowledge-base-static-data)
4. [News Ingestion — Is It Live?](#4-news-ingestion--is-it-live)
5. [AI Content Generation](#5-ai-content-generation)
6. [Editorial Review](#6-editorial-review)
7. [Visual Generation](#7-visual-generation)
8. [Publishing & Scheduling](#8-publishing--scheduling)
9. [Full End-to-End Walkthrough](#9-full-end-to-end-walkthrough)
10. [What Needs API Keys](#10-what-needs-api-keys)
11. [Command Quick Reference](#11-command-quick-reference)

---

## 1. Big Picture — The Pipeline

```
┌─────────────────────────────────────────────────────────────────────┐
│                        ANTI-CORRUPT PIPELINE                        │
│                                                                     │
│  ┌──────────────┐    ┌───────────────┐    ┌──────────────────────┐ │
│  │  KNOWLEDGE   │    │     NEWS      │    │   AI GENERATION      │ │
│  │    BASE      │───▶│  INGESTION    │───▶│  (Claude / GPT)      │ │
│  │ (YAML files) │    │  (RSS feeds)  │    │                      │ │
│  └──────────────┘    └───────────────┘    └──────────┬───────────┘ │
│         │                                             │             │
│         │   context injected into prompts             │ draft saved │
│         └─────────────────────────────────────────────▼            │
│                                            ┌──────────────────────┐ │
│                                            │  EDITORIAL REVIEW    │ │
│                                            │  (approve / reject)  │ │
│                                            └──────────┬───────────┘ │
│                                                       │ approved    │
│                                            ┌──────────▼───────────┐ │
│                                            │  VISUAL GENERATION   │ │
│                                            │  (PNG carousel etc.) │ │
│                                            └──────────┬───────────┘ │
│                                                       │ images ready│
│                                            ┌──────────▼───────────┐ │
│                                            │  PUBLISHING          │ │
│                                            │  (Instagram / X)     │ │
│                                            └──────────────────────┘ │
└─────────────────────────────────────────────────────────────────────┘
```

Each stage is **independent** — you can run any stage in isolation without
needing the previous one to have been done with real data. Dry-run and mock
modes exist throughout.

---

## 2. Where Data Is Stored

Everything is local to your machine. Nothing is uploaded to any cloud by
default.

```
anti_corrupt/
│
├── data/                    ← STATIC — version-controlled YAML knowledge base
│   ├── institutions/        ← 7 Brazilian institutions (STF, Senado, Câmara…)
│   ├── figures/             ← 3 public figures (Moraes, Lula, Pacheco)
│   ├── events/              ← 3 historical events (Lava Jato, Constituição…)
│   ├── relationships/       ← 9 graph edges connecting the entities above
│   └── glossary/            ← political/legal terms
│
└── output/                  ← DYNAMIC — generated at runtime, gitignored
    ├── drafts.db            ← SQLite — all AI-generated drafts (every status)
    ├── schedule.db          ← SQLite — scheduled posts queue
    ├── api_cache.db         ← SQLite — cached API responses (Câmara etc.)
    ├── drafts/              ← (legacy folder, kept for compatibility)
    ├── approved/            ← (reserved for export, not yet used)
    ├── published/           ← (reserved for archive)
    └── images/              ← PNG files generated by `visuals` commands
        ├── diagram_lei.png
        ├── diagram_stf.png
        ├── network_stf.png
        ├── timeline_lava-jato.png
        ├── profile_alexandre-de-moraes.png
        └── <draft-id>/      ← one folder per carousel
            ├── slide_01.png
            └── slide_02.png
```

### `drafts.db` — the heart of the system

Every piece of AI-generated content goes into this SQLite database. A draft
has a status that moves through a state machine:

```
raw → draft → pending_review → approved → published
                    └──────────→ rejected → draft (re-edit)
```

The 8-character draft ID (e.g. `383badc1`) is what you use in every
subsequent command to reference the same piece of content.

---

## 3. Knowledge Base (static data)

**What it is:** Hand-curated YAML files that describe Brazilian institutions,
public figures, historical events, relationships between them, and a glossary.
This data is **version-controlled** in `data/` and checked into git.

**What it is NOT:** A live database. It doesn't auto-update. You (or the team)
edit the YAML files to add or correct information.

**How it feeds the AI:** When you generate an explainer for `stf`, the system
loads `data/institutions/supremo_tribunal_federal.yaml`, pulls the
relationships graph, and injects all of that as context into the LLM prompt.
The AI is not browsing the internet — it's working with your curated facts.

### Exploring the knowledge base

```bash
# Stats overview
anticorrupt kb stats

# Validate all YAML files against their schemas
anticorrupt kb validate

# Full-text search across everything
anticorrupt kb search "supremo tribunal"
anticorrupt kb search "lava jato"

# Show relationship graph for an entity
anticorrupt kb graph --entity stf
anticorrupt kb graph --entity congresso-nacional

# Show what's connected to a specific figure
anticorrupt kb graph --entity alexandre-de-moraes
```

### Adding new data

Just create a new YAML file in the right folder following the `_schema.yaml`
in each directory. Then run `anticorrupt kb validate` to check it.

```bash
# Example: add a new institution
cp data/institutions/senado_federal.yaml data/institutions/tribunal_de_contas.yaml
# edit the file…
anticorrupt kb validate
```

---

## 4. News Ingestion — Is It Live?

**Yes — RSS is live.** When you run `anticorrupt news scan`, it makes real
HTTP requests to the RSS feeds right now.

### The feeds registered

| Key | Source | Tags |
|---|---|---|
| `folha_poder` | Folha de S.Paulo — Poder | política, governo |
| `g1_politica` | G1 — Política | política |
| `estadao_politica` | Estadão — Política | política, governo |
| `congresso_em_foco` | Congresso em Foco | congresso, legislativo |
| `agencia_brasil` | Agência Brasil (EBC) | governo, oficial |
| `agencia_senado` | Agência Senado | senado, legislativo |
| `agencia_camara` | Agência Câmara | câmara, legislativo |
| `stf_noticias` | STF — Notícias | judiciário, stf |
| `jota` | JOTA | judiciário, direito |

### What is and isn't cached

- **RSS articles are NOT cached** — every `news scan` hits the feeds live.
  Articles are ephemeral; they're only held in memory during the command.
- **If you run `news summarize`**, the resulting AI-written summaries ARE
  saved to `drafts.db` permanently.
- **Câmara API responses** (from `sources refresh`) ARE cached in
  `api_cache.db` with a 24-hour TTL so you don't hammer the government API.

### Commands

```bash
# See the latest headlines right now (no AI, no key needed)
anticorrupt news scan
anticorrupt news scan --source stf_noticias      # one feed only
anticorrupt news scan --limit 10                 # top 10 per feed
anticorrupt news scan --all                      # include English sources too

# Summarize with AI and save drafts (needs ANTHROPIC_API_KEY)
anticorrupt news summarize
anticorrupt news summarize --limit 3             # process top 3 articles
anticorrupt news summarize --dry-run             # mock AI, no real API call
anticorrupt news summarize --submit              # auto-submit to review queue
```

---

## 5. AI Content Generation

**Requires:** `ANTHROPIC_API_KEY` (or `OPENAI_API_KEY`) in your `.env` file.
Use `--dry-run` on any command to test the flow with a mock LLM response.

### How the AI gets context

Before calling Claude/GPT, the system builds a prompt that includes:

1. The entity's full YAML data (e.g. all fields from `supremo_tribunal_federal.yaml`)
2. Related entities from the relationship graph (e.g. STF's connection to the Presidência)
3. Editorial rules from `config/editorial_rules.yaml` (tone: educational, non-partisan)
4. The output format instructions (structured sections in Portuguese)

The LLM never sees the internet — it only sees what you've curated.

### Content types you can generate

```bash
# Institutional explainer — "Como funciona o STF?"
anticorrupt generate explainer --institution stf
anticorrupt generate explainer --institution camara-deputados
anticorrupt generate explainer --institution senado-federal

# All institution IDs available:
#   stf, congresso-nacional, senado-federal, camara-deputados,
#   tse, mpf, presidencia-da-republica

# Public figure profile
anticorrupt generate profile alexandre-de-moraes
anticorrupt generate profile luiz-inacio-lula-da-silva
anticorrupt generate profile rodrigo-pacheco

# Historical timeline narrative
anticorrupt generate timeline lava-jato
anticorrupt generate timeline impeachment-dilma-2016

# Format a draft for a specific platform (after generating)
anticorrupt generate format <draft-id> --platform instagram
anticorrupt generate format <draft-id> --platform twitter

# Dry-run any command (mock AI response, no API call)
anticorrupt generate explainer --institution stf --dry-run
```

### What gets saved

Every generation saves a `ContentDraft` to `drafts.db`:

- **Without `--submit`**: status = `draft`. Shows in review as a draft.
- **With `--submit`**: status = `pending_review`. Shows in the review queue.

The draft stores: the body text, AI model used, token count, estimated cost
in USD, the source entity IDs, and tags.

---

## 6. Editorial Review

This is the human-in-the-loop step. **No API keys needed.**

The review queue is just a filtered view of `drafts.db`.

```bash
# See everything
anticorrupt review list
anticorrupt review list --status pending_review
anticorrupt review list --status approved
anticorrupt review list --type institution_explainer

# Read a full draft
anticorrupt review show <draft-id>

# Approve it (moves to approved — ready to publish)
anticorrupt review approve <draft-id>
anticorrupt review approve <draft-id> --note "Revisado e aprovado"

# Reject it (goes back to draft for rework)
anticorrupt review reject <draft-id> --reason "Muito longo"

# Stats snapshot
anticorrupt review stats
```

A draft must be `approved` before you can publish it. This is enforced in the
`send` and `schedule` commands.

---

## 7. Visual Generation

**No API keys needed.** All images are generated locally using Pillow
(Python image library) and matplotlib. No external service is called.

Output files are saved to `output/images/`.

```bash
# ── Institutional flowcharts ────────────────────────────────────────────
# See what diagrams are available
anticorrupt visuals list-diagrams
# → lei, impeachment, stf

# Render one
anticorrupt visuals diagram lei
anticorrupt visuals diagram impeachment
anticorrupt visuals diagram stf
# Output: output/images/diagram_<name>.png

# ── Network relationship graph ───────────────────────────────────────────
# Shows an entity and all its connections from the knowledge base
anticorrupt visuals network stf
anticorrupt visuals network congresso-nacional
# Output: output/images/network_<entity-id>.png

# ── Public figure profile card ───────────────────────────────────────────
anticorrupt visuals profile alexandre-de-moraes
anticorrupt visuals profile luiz-inacio-lula-da-silva
# Output: output/images/profile_<figure-id>.png

# ── Event timeline ────────────────────────────────────────────────────────
anticorrupt visuals timeline lava-jato
anticorrupt visuals timeline impeachment-dilma-2016
# Output: output/images/timeline_<group>.png

# ── Instagram carousel (from an approved draft) ───────────────────────────
anticorrupt visuals carousel <draft-id>              # generates PNGs
anticorrupt visuals carousel <draft-id> --dry-run    # preview slide text only
# Output: output/images/<draft-id>/slide_01.png, slide_02.png, …
```

### Image dimensions

| Type | Size | Platform |
|---|---|---|
| Carousel slide | 1080 × 1080 px | Instagram square |
| Profile card | 1080 × 1080 px | Instagram square |
| Timeline | 1200 × 675 px | Landscape / Twitter |
| Network graph | 1200 × 675 px | Landscape / Twitter |
| Flowchart | 900 × 600 px | General purpose |

---

## 8. Publishing & Scheduling

### Live publishing (needs platform credentials)

The `send` command makes a real API call:

```bash
# Instagram — requires INSTAGRAM_ACCESS_TOKEN + INSTAGRAM_BUSINESS_ACCOUNT_ID
anticorrupt publish send <draft-id> --platform instagram \
    --image-url https://yourhost.com/slide_01.jpg \
    --image-url https://yourhost.com/slide_02.jpg

# X/Twitter — requires TWITTER_* keys
anticorrupt publish send <draft-id> --platform twitter

# Always test first with --dry-run (no real request sent)
anticorrupt publish send <draft-id> --platform instagram \
    --image-url https://example.com/img.jpg \
    --dry-run
```

**Important for Instagram:** The API requires publicly accessible image URLs
— you can't upload a local file directly. You need to host your PNGs somewhere
(e.g. S3, Cloudflare Images, even a public GitHub release asset) and pass the
URLs. X/Twitter reads local files from `output/images/<draft-id>/`.

### Scheduling (no credentials needed to queue — only to execute)

```bash
# Add to queue (stored in output/schedule.db)
anticorrupt publish schedule <draft-id> \
    --platform instagram \
    --time "2026-03-01T10:00" \
    --image-url https://yourhost.com/slide_01.jpg

# See the queue
anticorrupt publish queue
anticorrupt publish queue --all          # include done/failed

# Execute all due posts
anticorrupt publish run-due
anticorrupt publish run-due --dry-run    # preview without posting

# View performance metrics after publishing
anticorrupt publish analytics <draft-id>
anticorrupt publish analytics <draft-id> --fetch    # refresh from API
```

You can run `anticorrupt publish run-due` as a cron job:

```bash
# crontab — run every 5 minutes
*/5 * * * * cd /path/to/anti_corrupt && uv run anticorrupt publish run-due
```

---

## 9. Full End-to-End Walkthrough

This is the complete flow from zero to a published Instagram post.

### Step 1 — Set up credentials

```bash
cp .env.example .env
# Edit .env — add at minimum: ANTHROPIC_API_KEY
```

### Step 2 — Check the knowledge base

```bash
anticorrupt kb stats
anticorrupt kb search "STF"
```

### Step 3 — Generate an explainer

```bash
anticorrupt generate explainer --institution stf --submit
# → prints draft ID, e.g. "a1b2c3d4"
# → status: pending_review
```

### Step 4 — Review and approve

```bash
anticorrupt review list --status pending_review
anticorrupt review show a1b2c3d4
anticorrupt review approve a1b2c3d4
```

### Step 5 — Format for Instagram

```bash
anticorrupt generate format a1b2c3d4 --platform instagram
# → writes the carousel script into draft.formatted
```

### Step 6 — Render the carousel PNGs

```bash
anticorrupt visuals carousel a1b2c3d4
# → output/images/a1b2c3d4/slide_01.png
# → output/images/a1b2c3d4/slide_02.png
```

### Step 7 — Host the images

Upload the PNGs to any public hosting (S3, GitHub release, Cloudflare R2…)
and get public HTTPS URLs.

### Step 8 — Publish or schedule

```bash
# Publish now
anticorrupt publish send a1b2c3d4 --platform instagram \
    --image-url https://yourcdn.com/a1b2c3d4/slide_01.png \
    --image-url https://yourcdn.com/a1b2c3d4/slide_02.png

# Or schedule for tomorrow at 10:00 UTC
anticorrupt publish schedule a1b2c3d4 \
    --platform instagram \
    --time "2026-03-02T13:00" \
    --image-url https://yourcdn.com/a1b2c3d4/slide_01.png \
    --image-url https://yourcdn.com/a1b2c3d4/slide_02.png
```

---

## 10. What Needs API Keys

| Feature | Key needed | Where to get it | Cost |
|---|---|---|---|
| AI generation | `ANTHROPIC_API_KEY` | console.anthropic.com | ~$0.003–$0.015/draft |
| AI generation (alt) | `OPENAI_API_KEY` | platform.openai.com | ~$0.002–$0.010/draft |
| News scanning | None | — | Free |
| Knowledge base | None | — | Free |
| Visual generation | None | — | Free |
| Instagram publishing | `INSTAGRAM_ACCESS_TOKEN` + `INSTAGRAM_BUSINESS_ACCOUNT_ID` | Facebook Developer portal | Free (requires Business account) |
| X/Twitter publishing | 5× `TWITTER_*` keys | developer.twitter.com | $100/mo (Basic) for write access |
| Câmara API (`sources refresh`) | None | dadosabertos.camara.leg.br | Free |

### Testing without real keys

Every command that calls an AI API accepts `--dry-run`. This uses a
`MockLLMClient` that returns a canned response — the full pipeline still
runs (YAML is loaded, prompts are built, draft is saved, images can be
rendered) but no real API call is made and no cost is incurred.

```bash
anticorrupt generate explainer --institution stf --dry-run
anticorrupt news summarize --dry-run
anticorrupt publish send <id> --platform instagram --image-url https://x.com/img.jpg --dry-run
```

---

## 11. Command Quick Reference

```bash
# ─── Knowledge Base ─────────────────────────────────────────────────────────
anticorrupt kb validate                    # validate all YAML files
anticorrupt kb stats                       # counts per category
anticorrupt kb search "<query>"            # full-text search
anticorrupt kb graph --entity <id>         # show entity connections

# ─── News ────────────────────────────────────────────────────────────────────
anticorrupt news scan                      # list latest headlines (live RSS)
anticorrupt news scan --source agencia_senado
anticorrupt news summarize                 # AI-summarize → save drafts
anticorrupt news summarize --dry-run       # mock AI, no cost

# ─── Generate ────────────────────────────────────────────────────────────────
anticorrupt generate explainer --institution stf
anticorrupt generate profile alexandre-de-moraes
anticorrupt generate timeline lava-jato
anticorrupt generate format <draft-id> --platform instagram
# Add --dry-run to any generate command to skip real AI call
# Add --submit to auto-move to pending_review

# ─── Review ──────────────────────────────────────────────────────────────────
anticorrupt review list
anticorrupt review list --status approved
anticorrupt review show <draft-id>
anticorrupt review approve <draft-id>
anticorrupt review reject <draft-id> --reason "..."
anticorrupt review stats

# ─── Visuals ─────────────────────────────────────────────────────────────────
anticorrupt visuals list-diagrams
anticorrupt visuals diagram <name>         # lei | impeachment | stf
anticorrupt visuals network <entity-id>
anticorrupt visuals profile <figure-id>
anticorrupt visuals timeline <group>
anticorrupt visuals carousel <draft-id>
anticorrupt visuals carousel <draft-id> --dry-run

# ─── Publish ─────────────────────────────────────────────────────────────────
anticorrupt publish preview <draft-id>
anticorrupt publish send <draft-id> --platform instagram --image-url <url>
anticorrupt publish send <draft-id> --platform twitter
anticorrupt publish schedule <draft-id> --time "2026-03-01T10:00" --platform instagram
anticorrupt publish queue
anticorrupt publish run-due
anticorrupt publish run-due --dry-run
anticorrupt publish analytics <draft-id>

# ─── Sources / Cache ─────────────────────────────────────────────────────────
anticorrupt sources status                 # show cache stats
anticorrupt sources refresh                # pull fresh data from Câmara API
anticorrupt sources snapshot               # export cache to JSON snapshot
anticorrupt sources invalidate <source>    # force refresh a specific source

# ─── Dashboard ───────────────────────────────────────────────────────────────
anticorrupt dashboard                      # quick overview
```
